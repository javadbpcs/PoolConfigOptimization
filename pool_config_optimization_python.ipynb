{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run pool_config_optimization_python_functions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('igs_10_16_pool_report.json') \n",
    "data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_pool_config = {'auto_shutdown': 10, 'min_idle_vm': 0}\n",
    "\n",
    "auto_shutdown_grid = [1, 2, 3, 4, 5, 6, 10]\n",
    "min_idle_vm_grid = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
    "\n",
    "if len(base_pool_config)>0:\n",
    "    if base_pool_config['auto_shutdown'] not in auto_shutdown_grid:\n",
    "        auto_shutdown_grid.append(base_pool_config['auto_shutdown'])\n",
    "    if base_pool_config['min_idle_vm'] not in min_idle_vm_grid:\n",
    "        min_idle_vm_grid.append(base_pool_config['min_idle_vm']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating clusters dataframe\n",
    "clusters_pd = cluster_df(data)\n",
    "\n",
    "# creating contentionTimelines dataframe\n",
    "contentionTimelines_pd = contentionTimelines_df(data)\n",
    "\n",
    "# merging two dataframes\n",
    "cluster_contention_pd = contentionTimelines_pd.merge(clusters_pd, on='clusterId', how='left')\n",
    "\n",
    "# filtering for only job clusters\n",
    "cluster_contention_jc_pd=cluster_contention_pd[cluster_contention_pd.clusterType=='JOB_CLUSTER']\n",
    "\n",
    "# creating cluster timeline dataframe\n",
    "cluster_timelines_pd =  cluster_timeline_df(cluster_contention_jc_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duration is 8.42 seconds\n",
      "The rate of improvements in using pool resources will be 42.4%\n",
      "The optimal suggested pool config is {'auto_shutdown': 1, 'min_idle_vm': 0}\n"
     ]
    }
   ],
   "source": [
    "greedy_df = pd.DataFrame(columns=['auto_shutdown', 'min_idle_vm', 'total_idle_time',\n",
    "                                  'idle_vm_count', 'cold_start_cnt', 'warm_start_cnt',])\n",
    "cnt = 0\n",
    "t1 = time.time()\n",
    "for auto_shutdown in auto_shutdown_grid:\n",
    "\n",
    "    # step 2\n",
    "    cluster_groups = grouper(cluster_timelines_pd, auto_shutdown)\n",
    "\n",
    "\n",
    "    # Adding group number to cluster_timelines_pd\n",
    "    cluster_timelines_pd = cluster_timeline_update(cluster_timelines_pd, cluster_groups)\n",
    "\n",
    "\n",
    "    # step 3\n",
    "    total_groups_distance, cluster_groups = group_intervals(cluster_groups)\n",
    "\n",
    "    # step 4, part B\n",
    "    vm_usage_classes = vm_usage_v4(cluster_groups, cluster_timelines_pd, cluster_contention_jc_pd, auto_shutdown)\n",
    "\n",
    "\n",
    "    # groups summary and stats\n",
    "    groups_summary_org = groups_stats_v2(vm_usage_classes)\n",
    "\n",
    "    # calculating total idle time in sec\n",
    "    total_idle_time_org = groups_summary_org.idle_duration.sum()\n",
    "\n",
    "\n",
    "    ## Part g: add effects of min_idle_vm\n",
    "    for min_idle_vm in min_idle_vm_grid:\n",
    "        total_idle_time, groups_summary = min_idle_vm_effect_v2(min_idle_vm, total_idle_time_org,\n",
    "                                                             total_groups_distance, groups_summary_org)\n",
    "\n",
    "        # creating greedy dataframe\n",
    "        greedy_df.loc[cnt] = [None]*len(greedy_df.columns)\n",
    "        greedy_df['auto_shutdown'].loc[cnt] = auto_shutdown\n",
    "        greedy_df['min_idle_vm'].loc[cnt] = min_idle_vm\n",
    "        greedy_df['total_idle_time'].loc[cnt] = total_idle_time\n",
    "        \n",
    "        greedy_df['idle_vm_count'].loc[cnt] = groups_summary.idle_vm_count.sum()\n",
    "        greedy_df['cold_start_cnt'].loc[cnt] = groups_summary.cold_start_cnt.sum()\n",
    "        greedy_df['warm_start_cnt'].loc[cnt] = groups_summary.warm_start_cnt.sum()\n",
    "        cnt+=1\n",
    "\n",
    "\n",
    "# finding optimal config       \n",
    "opt_config = optimal_config(greedy_df)\n",
    "t2 = time.time()\n",
    "print(f'duration is {np.round(t2-t1,2)} seconds')\n",
    "# calculating amount of improvements comapred to baseline usage\n",
    "if len(base_pool_config)>0:\n",
    "    percent_improvements = improvements(greedy_df, base_pool_config)\n",
    "    print(f'The rate of improvements in using pool resources will be {percent_improvements}%')\n",
    "    \n",
    "print(f'The optimal suggested pool config is {opt_config}')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
